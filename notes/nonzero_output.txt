(venv) (base) anooprehman@anoop-air-2 324-project % python hear_outputs.py
/Users/anooprehman/Documents/uoft/sem6/ece324/group_project/324-project/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
Input src shape: torch.Size([1, 10, 5])
tensor([[[ 3.2552e-02, -2.2135e-02,  1.0417e-02,  5.2000e+01,  5.5000e+01],
         [ 4.1667e-02,  6.3802e-02,  9.6354e-02,  6.9000e+01,  6.6000e+01],
         [ 4.2969e-02, -2.8646e-02,  1.3021e-02,  6.3000e+01,  6.0000e+01],
         [ 7.2917e-02, -5.8594e-02, -1.5625e-02,  8.0000e+01,  8.4000e+01],
         [ 3.1250e-02,  5.4688e-02,  1.2760e-01,  6.4000e+01,  7.1000e+01],
         [ 4.5573e-02, -2.2135e-02,  9.1146e-03,  5.2000e+01,  5.9000e+01],
         [ 8.8542e-02, -3.6458e-02,  9.1146e-03,  7.6000e+01,  7.6000e+01],
         [ 4.2969e-02,  1.4193e-01,  2.3047e-01,  6.8000e+01,  6.2000e+01],
         [ 8.2031e-02, -4.1667e-02,  1.3021e-03,  7.1000e+01,  6.0000e+01],
         [ 3.9062e-02, -2.0833e-02,  6.1198e-02,  4.7000e+01,  7.2000e+01],
         [ 3.2785e-02, -5.0287e-04,  1.6738e-02,  3.8807e-01,  4.6085e-01],
         [ 3.2785e-02, -5.0287e-04,  1.6738e-02,  3.8807e-01,  4.6085e-01],
         [ 2.7394e-02, -1.3106e-03,  1.3191e-02, -4.7389e-01, -3.0848e-01],
         [ 2.7419e-02, -1.3109e-03,  1.3175e-02, -4.7171e-01, -3.1112e-01],
         [ 2.7453e-02, -1.3095e-03,  1.3167e-02, -4.6878e-01, -3.1133e-01],
         [ 2.7492e-02, -1.3066e-03,  1.3168e-02, -4.6478e-01, -3.0980e-01],
         [ 2.7523e-02, -1.3044e-03,  1.3168e-02, -4.6155e-01, -3.0886e-01],
         [ 2.7552e-02, -1.3021e-03,  1.3170e-02, -4.5833e-01, -3.0782e-01],
         [ 2.7580e-02, -1.2999e-03,  1.3172e-02, -4.5507e-01, -3.0688e-01],
         [ 2.7606e-02, -1.2978e-03,  1.3173e-02, -4.5200e-01, -3.0602e-01],
         [ 2.7635e-02, -1.2956e-03,  1.3175e-02, -4.4895e-01, -3.0474e-01],
         [ 2.7665e-02, -1.2932e-03,  1.3177e-02, -4.4582e-01, -3.0338e-01],
         [ 2.7696e-02, -1.2907e-03,  1.3179e-02, -4.4255e-01, -3.0188e-01],
         [ 2.7728e-02, -1.2882e-03,  1.3181e-02, -4.3924e-01, -3.0036e-01],
         [ 2.7761e-02, -1.2854e-03,  1.3184e-02, -4.3568e-01, -2.9874e-01],
         [ 2.7795e-02, -1.2824e-03,  1.3189e-02, -4.3183e-01, -2.9674e-01],
         [ 2.7831e-02, -1.2791e-03,  1.3195e-02, -4.2787e-01, -2.9452e-01],
         [ 2.7867e-02, -1.2758e-03,  1.3201e-02, -4.2389e-01, -2.9213e-01],
         [ 2.7901e-02, -1.2726e-03,  1.3207e-02, -4.2009e-01, -2.8988e-01],
         [ 2.7934e-02, -1.2694e-03,  1.3214e-02, -4.1622e-01, -2.8762e-01],
         [ 2.7968e-02, -1.2662e-03,  1.3220e-02, -4.1232e-01, -2.8538e-01],
         [ 2.7998e-02, -1.2633e-03,  1.3226e-02, -4.0877e-01, -2.8341e-01],
         [ 2.8029e-02, -1.2603e-03,  1.3232e-02, -4.0521e-01, -2.8136e-01],
         [ 2.8060e-02, -1.2574e-03,  1.3238e-02, -4.0171e-01, -2.7928e-01],
         [ 2.8090e-02, -1.2545e-03,  1.3244e-02, -3.9828e-01, -2.7712e-01],
         [ 2.8120e-02, -1.2516e-03,  1.3250e-02, -3.9484e-01, -2.7497e-01],
         [ 2.8150e-02, -1.2487e-03,  1.3256e-02, -3.9146e-01, -2.7285e-01],
         [ 2.8179e-02, -1.2458e-03,  1.3262e-02, -3.8813e-01, -2.7078e-01],
         [ 2.8208e-02, -1.2430e-03,  1.3269e-02, -3.8474e-01, -2.6867e-01],
         [ 2.8237e-02, -1.2400e-03,  1.3276e-02, -3.8117e-01, -2.6656e-01],
         [ 2.8262e-02, -1.2374e-03,  1.3282e-02, -3.7798e-01, -2.6480e-01],
         [ 2.8288e-02, -1.2349e-03,  1.3288e-02, -3.7487e-01, -2.6304e-01],
         [ 2.8312e-02, -1.2324e-03,  1.3294e-02, -3.7185e-01, -2.6128e-01],
         [ 2.8337e-02, -1.2299e-03,  1.3300e-02, -3.6883e-01, -2.5953e-01],
         [ 2.8362e-02, -1.2273e-03,  1.3306e-02, -3.6569e-01, -2.5771e-01],
         [ 2.8386e-02, -1.2247e-03,  1.3313e-02, -3.6259e-01, -2.5588e-01],
         [ 2.8409e-02, -1.2223e-03,  1.3319e-02, -3.5962e-01, -2.5419e-01],
         [ 2.8432e-02, -1.2200e-03,  1.3325e-02, -3.5673e-01, -2.5264e-01],
         [ 2.8454e-02, -1.2177e-03,  1.3330e-02, -3.5387e-01, -2.5113e-01],
         [ 2.8476e-02, -1.2155e-03,  1.3336e-02, -3.5100e-01, -2.4963e-01],
         [ 2.8498e-02, -1.2132e-03,  1.3342e-02, -3.4812e-01, -2.4809e-01],
         [ 2.8520e-02, -1.2108e-03,  1.3348e-02, -3.4521e-01, -2.4653e-01],
         [ 2.8542e-02, -1.2085e-03,  1.3354e-02, -3.4231e-01, -2.4499e-01],
         [ 2.8564e-02, -1.2062e-03,  1.3360e-02, -3.3937e-01, -2.4344e-01],
         [ 2.8586e-02, -1.2039e-03,  1.3366e-02, -3.3647e-01, -2.4193e-01],
         [ 2.8608e-02, -1.2016e-03,  1.3372e-02, -3.3356e-01, -2.4037e-01],
         [ 2.8630e-02, -1.1991e-03,  1.3379e-02, -3.3053e-01, -2.3869e-01],
         [ 2.8653e-02, -1.1966e-03,  1.3386e-02, -3.2744e-01, -2.3693e-01],
         [ 2.8675e-02, -1.1942e-03,  1.3393e-02, -3.2440e-01, -2.3522e-01],
         [ 2.8697e-02, -1.1917e-03,  1.3400e-02, -3.2141e-01, -2.3356e-01]]])
Embedding shape: torch.Size([1, 60, 5])